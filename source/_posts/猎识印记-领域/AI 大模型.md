---
title: AI 大模型
date: 2025-05-12 19:15:34
published: true
tags: 
categories: 
excerpt: 探索AI大模型的核心原理与应用
thumbnail: /img/文章封面/defaultcover.jpg
---

# AI 大模型：核心原理与实践

## 大模型运行机制简析

大语言模型基于深度学习技术构建，其复杂的内部运作可简化为三个关键步骤：

1. **掌握语言**：
   模型通过分析海量文本数据，学习"预测下文"的能力。它吸收了几乎所有可获取的文字资源，逐渐掌握了流畅自然的表达技巧。

2. **理解意图**：
   人类语言表达方式多样且灵活。模型经过特殊训练后，能够准确捕捉用户真实意图，将问题视为输入，生成符合情境的回应。

3. **优化输出**：
   对于同一问题，模型可以生成多种可能答案。通过人类反馈和强化学习，模型不断调整自己的输出规则，使回答更符合人类期待。

## 聊天机器人技术概览

聊天机器人是智能交互系统的前沿应用，能通过文本或语音与人类进行对话。其核心挑战包括：

- 如何判断输入语句的合理性与意图
- 如何生成自然流畅且符合人类表达习惯的回应

现代聊天机器人集成了多种技术能力：自然语言理解、对话管理、个性化交互和任务执行。这使它们能够准确识别用户需求、维持对话连贯性、提供个性化回答，并完成实际任务。

**应用领域**

聊天机器人已在多个领域展现价值：

- 客服领域：提供 24 小时自动化支持
- 娱乐互动：创造有趣的对话体验
- 教育辅助：提供个性化学习指导
- 智能家居：实现语音控制功能
- 医疗咨询：提供初步健康建议

**主流产品对比**

| 产品名称 | 开发机构     | 技术特点                   |
| -------- | ------------ | -------------------------- |
| DeepSeek | 杭州深度求索 | 高性能、开源、部署成本低   |
| Kimi     | 月之暗面     | 超长上下文理解、长文档处理 |
| 通义千问 | 阿里云       | 办公场景优化、信息处理高效 |
| 讯飞星火 | 科大讯飞     | 语音交互能力突出           |
| 豆包     | 字节跳动     | 抖音与今日头条内容整合     |

## DeepSeek 技术解析

DeepSeek-R1 模型技术表现突出，已与国际顶尖模型处于同一水平线。作为国产模型，它具备显著优势：训练成本低、响应速度快、完全开源、中文理解精准。

随着技术进步，大模型变得更加平民化。研究人员开发的"模型蒸馏"技术，能将强大模型的核心能力精华提取并传递给轻量级模型。这一技术使普通硬件也能运行高性能 AI 应用，大大降低了使用门槛。

接下来，我们将探索如何在个人电脑或云服务器上部署自己的 AI 助手。以 DeepSeek-R1 的 7b 参数模型为例（需要约 6GB 显存），我们将学习把模型文件转变为功能完善的对话系统的全过程。

# 本地部署大模型指南

不管是个人电脑还是云平台，搭建聊天机器人的步骤为：

1. 后端和模型部署：
   - 个人电脑：使用 ollama 框架搭配 deepseek 或 qwen 模型
   - 云平台：使用 LangChain 框架搭配阿里云百炼平台或通义千问
2. 前端部署：个人电脑或云平台均可使用 Streamlit

## ollama 简介

ollama 是一款简化大型语言模型本地部署和运行的开源软件，提供轻量级框架让开发者能在本地机器上轻松构建和管理 LLMs。
通过官方模型库(https://ollama.com/library)可查看所有支持的模型，包括deepseek、qwen、llava等。

## Windows 系统部署方法

在 Windows 上部署私有大模型只需两步：

1. 下载并安装 ollama
2. 终端中使用 ollama 命令安装大模型

## WSL 环境介绍

**为什么选择 WSL**

WSL 作为 Windows 10 带来的特性，相比传统虚拟机方式获取 Linux 环境更加轻量化。开发者正逐步从虚拟机转向 WSL，因为它简单、轻量且资源占用少。

**WSL 工作原理**

WSL 是 Windows 系统上的 Linux 子系统，可在 Windows 中获得 Linux 环境，直接连接计算机硬件而无需虚拟机。Windows 系统文件可通过`/mnt/c`或`/mnt/d`访问。

## CUDA 环境

CUDA 是 NVIDIA 推出的并行计算平台，让程序能利用 GPU 加速计算。WSL 安装 Ubuntu 后自动配置显卡驱动和 CUDA，可通过`nvidia-smi`命令验证。

## Linux 系统安装 ollama

### 方式一：一键安装

从官网获取 Linux 安装命令，但容易因网络问题失败。

### 方式二：手动安装（推荐）

1. **获取安装包**
   下载或从 Windows 复制安装包到 WSL

   ```
   cp /mnt/d/ollama-linux-amd64.tgz ~/
   ```

2. **解压安装**

   ```
   sudo tar -xvf ollama-linux-amd64.tgz -C /usr
   ```

3. **测试运行**

   ```
   ollama serve
   ```

   确认正常后按 Ctrl+C 退出

4. **创建系统用户**

   ```
   sudo useradd -r -s /bin/false -U -m -d /usr/share/ollama ollama
   sudo usermod -a -G ollama $(whoami)
   ```

5. **配置系统服务**

   ```
   sudo touch /etc/systemd/system/ollama.service
   # 编辑服务文件内容
   sudo systemctl daemon-reload
   ```

6. **服务管理命令**
   ```
   sudo systemctl enable ollama  # 开机自启
   sudo systemctl start ollama   # 启动服务
   sudo systemctl status ollama  # 查看状态
   sudo systemctl stop ollama    # 停止服务
   ```

## 大模型使用

### 下载模型

```
ollama pull deepseek-r1:7b
ollama pull qwen2:7b
```

### 运行模型

```
ollama run deepseek-r1:7b
```

本地部署大模型提供了私有、便捷的 AI 服务，无需担心数据泄露，同时享受大模型带来的便利。

## Chatbox 交互工具

Chatbox 是基于 OpenAI API 的开源跨平台智能对话工具，使用步骤：

1. 下载安装适合系统的安装包
2. 设置中选择 ollama 中本地部署的模型
3. 创建对话窗口开始使用
4. 聊天记录自动保存到本地